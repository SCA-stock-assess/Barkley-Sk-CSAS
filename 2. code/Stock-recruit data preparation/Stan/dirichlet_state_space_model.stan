// Code generated by ChatGPT based on description of the problem and 
// uploading the raw data file


data {
  int<lower=1> T;                       // Number of time points
  int<lower=2> K;                       // Number of composition categories
  vector<lower=0>[K] rate[T];           // Weight data (non-integer) for Dirichlet likelihood
  int<lower=0, upper=1> is_observed[T]; // Indicator for observed values
  simplex[K] prior_mean;                 // Informative prior on initial composition (e.g., historic average)
  vector<lower=0>[T] conc;               // Year-specific concentration parameter (weights/sample sizes)
  real<lower=0> sigma_prior;             // Lake-specific prior for sigma
}

parameters {
  simplex[K] theta_raw[T]; // Raw latent compositions for non-centered parameterization
  real<lower=0> sigma;     // Process noise
}

transformed parameters {
  simplex[K] theta[T];
  theta[1] = theta_raw[1];
  for (t in 2:T) {
    theta[t] = softmax(log(theta_raw[t]) * sigma);
  }
}

model {
  sigma ~ normal(sigma_prior, 0.5) T[0,]; // Lake-specific prior for sigma
  theta_raw[1] ~ dirichlet(prior_mean * 100); // Prior informed by historic average
    // using 100 to reflect reasonable confidence that the historic average should
  // be representative of the population under status quo conditions

  for (t in 2:T) {
    theta_raw[t] ~ dirichlet((theta[t-1] * sigma + 1e-6));
  }

  for (t in 1:T) {
    if (is_observed[t] == 1) {
      rate[t] ~ dirichlet(theta[t] * conc[t]); // Year-specific concentration parameter
    }
  }
}

